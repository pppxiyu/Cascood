{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82a0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7835cd",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and save data\n",
    "data = rawData('./data/ambulance/virginiaBeach_ambulance_timeData.csv')\n",
    "data = addOrigin(data, './data/rescueTeamLocation/rescueStations.txt')\n",
    "data = geoCoding(data.loc['2013-01-01' : '2013-12-31', :], './data/geocoded_saved/20130101-20131231.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a038ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data and build geoDataFrame\n",
    "data = reLoadData('./data/geocoded_saved/20160101-20161015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be131d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = readRoads('./data/roads/Streets.shp')\n",
    "roads = makeSurface4Lines(roads, './data/roads/Road_Surfaces.shp', scale = 2.7)\n",
    "roads = getWaterDepthOnRoads(roads, './data/inundation/tifData/depth_objID_35.tif', './data/inundation/croppedByRoads/croppedByRoads.tif') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider bridges in road network (PENDING)\n",
    "# bridges = gpd.read_file('./data/bridges/bridgePolygon.shp').to_crs(str(inundation.crs))\n",
    "# inundation_cropped = inundationCutter(inundation, bridges, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cd1c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "graph = roads2Graph(roads)\n",
    "# showGraphRoads(roads, graph)\n",
    "# NOTE: the graph is un-directed right now, the logic should be checked if changed to directed\n",
    "\n",
    "# read the location of rescue squads and attach them to nodes \n",
    "rescue = readRescue('./data/rescueTeamLocation/rescueStations.txt', 'EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91844a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional info for descriptive analysis\n",
    "# assign records to graph edges\n",
    "data = assignGraphEdge(data, roads, 'RescueSquadPoint', 'OriginRoadID', 'Origin2RoadDist')\n",
    "data = assignGraphEdge(data, roads, 'IncidentPoint', 'DestinationID', 'Destination2RoadDist')\n",
    "# # find nearest rescue station\n",
    "# data = nearestRescueStation(data, rescue)\n",
    "# find the top nearest rescue stations\n",
    "data = nearnessObediance(data, rescue, graph)\n",
    "# calculate shortest path length and ave speed\n",
    "data = assumedAveSpeed(data, rescue, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc86c11",
   "metadata": {},
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "670aab39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "display(data.loc[:, ['DispatchTime', 'EnRouteTime', 'TravelTime', 'ResponseTime']].mean())\n",
    "display(data['RescueSquadNumber'].value_counts())\n",
    "display(data['CallPriority'].value_counts())\n",
    "display(data['DayOfWeek'].value_counts())\n",
    "display(data['HourInDay'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "773de66d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def incidentMap(data, timeSelectStart, timeSelectEnd, sizeMax, ifLog):\n",
    "    # general spatial dist of incidents\n",
    "    if ifLog == True:\n",
    "        data['LogResponseTime'] = np.log2(data['ResponseTime'])\n",
    "        colorData = \"LogResponseTime\"\n",
    "        range_color = [0, 20]\n",
    "    elif ifLog == False:\n",
    "        colorData = \"ResponseTime\"\n",
    "        range_color = [0, 45000]\n",
    "    px.set_mapbox_access_token(open(\"mapboxToken.txt\").read())\n",
    "    dataSelected = data.loc[timeSelectStart: timeSelectEnd, :].dropna()\n",
    "    fig = px.scatter_mapbox(lat = dataSelected.IncidentPoint.y, lon = dataSelected.IncidentPoint.x, color = dataSelected.ResponseTime,\n",
    "                            color_continuous_scale = px.colors.sequential.Sunsetdark, range_color = range_color, \n",
    "                            size = dataSelected.ResponseTime,\n",
    "                            size_max = sizeMax, \n",
    "                            zoom = 9.5, width = 750, height = 500)\n",
    "    return fig\n",
    "\n",
    "def responsTimeScatter(data):\n",
    "    # show the surge of the response time\n",
    "    fig = go.Figure(data = go.Scatter(x = data.index, y = data['ResponseTime'], mode='markers', marker_color = data['ResponseTime'],)) \n",
    "    fig.update_layout(xaxis_title = \"Datatime\", yaxis_title = \"Response time (s)\",)\n",
    "    return fig\n",
    "\n",
    "def processingTimeProportionDist(data):\n",
    "    df = pd.DataFrame((data.EnRouteTime / data.ResponseTime))\n",
    "    df = df.rename(columns = {0: \"Proportion of Preparation Time\"})\n",
    "    fig = px.histogram(df, x = \"Proportion of Preparation Time\", \n",
    "                        nbins = 75, template = 'seaborn', histnorm = 'probability', opacity = 0.75,\n",
    "                        width = 700, height = 500)\n",
    "    fig.update_layout(yaxis_title = 'Probability')\n",
    "    return fig\n",
    "\n",
    "def proximityOrderDist(data):\n",
    "    df = data.copy()\n",
    "    df['Flooding'] = 'Normal'\n",
    "    df.loc['2016-10-08 11:59:59': '2016-10-09 23:59:59', ['Flooding']] = 'Flooding'\n",
    "    fig = px.histogram(df[df.NearestOrder < 10], \n",
    "                 x = \"NearestOrder\", \n",
    "    #              color = \"Flooding\", \n",
    "                 template = 'seaborn', \n",
    "                 histnorm = 'probability', \n",
    "                 barmode = \"overlay\",\n",
    "                 opacity = 0.75, \n",
    "                 width = 700, height = 500,\n",
    "                )\n",
    "    fig.update_layout(yaxis_title = 'Probability', xaxis_title = 'Proximity Order of Origins')\n",
    "    return fig\n",
    "\n",
    "def distanceIncreaseRatioDist(data):\n",
    "    fig = px.histogram(data[(data.DisobediancePathIncrease > 1)], \n",
    "                 x = \"DisobediancePathIncrease\", \n",
    "                 barmode = \"overlay\",\n",
    "                 template = 'seaborn', histnorm = 'probability', \n",
    "                 opacity = 0.75, \n",
    "                 width = 700, height = 500,)\n",
    "    fig.update_traces(xbins = dict(start = 1, end = 2, size = 0.1))\n",
    "    fig.update_layout(yaxis_title = 'Probability', xaxis_title = 'Travel Distance Increase Percentage')\n",
    "    return fig\n",
    "\n",
    "def responseTimeWithCallPriorityDist(data):\n",
    "    fig = px.histogram(data[data.ResponseTime < 5000], \n",
    "                 x = \"ResponseTime\", \n",
    "                 color = \"CallPriority\", \n",
    "                 barmode = \"overlay\",\n",
    "                 template = 'seaborn', \n",
    "                 histnorm = 'probability', \n",
    "                 opacity = 0.75, \n",
    "                 width = 700, height = 500,\n",
    "                 nbins = 200, \n",
    "                )\n",
    "    fig.update_layout(yaxis_title = 'Probability', xaxis_title = 'Response Time')\n",
    "    return fig\n",
    "\n",
    "def averageSpeedPercentStd(data):\n",
    "    # np.histogram(data.groupby(['OriginRoadID', 'DestinationID']).count().AverageSpeed.values, 10, range = (5, 100)) # keep about 25% of OD when set freqencey above 5\n",
    "    dataSelect = data.loc[:, ['OriginRoadID', 'DestinationID', 'AverageSpeed']]\n",
    "    groupByODCount = dataSelect.groupby(['OriginRoadID', 'DestinationID']).count() # any columns indicates count\n",
    "    groupByODSpeed = dataSelect.groupby(['OriginRoadID', 'DestinationID']).mean()[groupByODCount.AverageSpeed >= 5].rename(columns = {'AverageSpeed': 'AverageSpeed_mean'})\n",
    "    groupByODSpeed['AverageSpeed_std'] = dataSelect.groupby(['OriginRoadID', 'DestinationID']).std()[groupByODCount.AverageSpeed >= 5]\n",
    "    groupByODSpeed['AverageSpeed_stdPercent'] = groupByODSpeed['AverageSpeed_std'] / groupByODSpeed['AverageSpeed_mean']\n",
    "    df = groupByODSpeed['AverageSpeed_stdPercent'].reset_index()\n",
    "    OriginNum = df.OriginRoadID\n",
    "    for origin, num in zip(pd.unique(df.OriginRoadID), range(1, pd.unique(df.OriginRoadID).shape[0] + 1)):\n",
    "        OriginNum = OriginNum.replace(origin, num)\n",
    "    df['OriginNum'] = OriginNum\n",
    "    fig = px.box(df, x = 'OriginNum', y = \"AverageSpeed_stdPercent\", template = 'seaborn', width = 500, height = 750, range_y = (0, 6.5), points = 'suspectedoutliers')\n",
    "    fig.update_layout(yaxis_title = 'Average Speed Percentage Standard Deviation', xaxis_title = 'Rescue Squad Number')\n",
    "    return fig\n",
    "\n",
    "def showWaterOnRoads(roads, figsize = (100, 50), vmax = 6):\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    roadsLineWater = roads.loc[:, ['line', 'waterDepth']].set_geometry('line')\n",
    "    ax = roadsLineWater.plot(ax = ax, \n",
    "                        column = 'waterDepth', \n",
    "                        zorder = 5, \n",
    "                        cmap = 'OrRd',\n",
    "                        legend = True,\n",
    "                        vmax = vmax,\n",
    "                       )\n",
    "    cx.add_basemap(ax, crs = roads.crs, source = cx.providers.CartoDB.Positron)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "def showTravelUpRatioOnRoads(roads, figsize = (100, 50), vmax = 10):\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    roadsLineWater = roads.loc[:, ['line', 'travelTimeIncreaseRatio']].set_geometry('line')\n",
    "    ax = roadsLineWater.plot(ax = ax, \n",
    "                        column = 'travelTimeIncreaseRatio', \n",
    "                        zorder = 5, \n",
    "                        cmap = 'OrRd',\n",
    "                        legend = True,\n",
    "                        vmax = vmax,\n",
    "                        vmin = 1,\n",
    "                       )\n",
    "    cx.add_basemap(ax, crs = roads.crs, source = cx.providers.CartoDB.Positron)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "def showAveTime(time, by):\n",
    "    dataGroupByHour = data.loc[:, [time, by]].groupby(by).mean()\n",
    "    fig = px.bar(dataGroupByHour.reset_index(), y = time, x = by, text_auto='.3s',)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7306d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processingTimeProportionDist(data)\n",
    "# proximityOrderDist(data)\n",
    "# distanceIncreaseRatioDist(data)\n",
    "# responseTimeWithCallPriorityDist(data)\n",
    "# averageSpeedPercentStd(data)\n",
    "\n",
    "# incidentMap(data, '2016-10-08', '2016-10-09', 16, False)\n",
    "# responsTimeScatter(data)\n",
    "\n",
    "# showWaterOnRoads(roads, (50, 25), 6)\n",
    "# showTravelUpRatioOnRoads(roads, (20, 12), 10)\n",
    "\n",
    "# showAveTime('ResponseTime', 'HourInDay')\n",
    "# showAveTime('ResponseTime', 'DayOfWeek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e5395",
   "metadata": {},
   "source": [
    "# Disruption analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97f875e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _addPathLen2Graph(graph, rescue, weight, newAttribute_rescueSquad, newAttribute_path):\n",
    "    # some roads are disconnected from all the rescue station even in normal time (as the raw data indicates)\n",
    "    voronoi = nx.voronoi_cells(graph, set(rescue.OBJECTID_nearestRoad.unique()), weight = weight)\n",
    "    for rescueSquad, destinations in zip(voronoi.keys(), voronoi.values()):\n",
    "        if rescueSquad == 'unreachable':\n",
    "            print(len(destinations), 'nodes are unreachable when building voronoi for', newAttribute_path)\n",
    "            for des in destinations:\n",
    "                graph.nodes[des][newAttribute_rescueSquad] = np.nan\n",
    "                graph.nodes[des][newAttribute_path] = math.inf # set path len to inf if it's disconnected from rescues\n",
    "#                 print('NOTE: node', des, 'is unreachable when building voronoi for', newAttribute_path)\n",
    "        else:\n",
    "            for des in destinations:\n",
    "                shortestPath = nx.shortest_path_length(graph, source = rescueSquad, target = des, weight = weight)\n",
    "                graph.nodes[des][newAttribute_path] = shortestPath\n",
    "                graph.nodes[des][newAttribute_rescueSquad] = rescueSquad\n",
    "                if shortestPath == 0:\n",
    "                    graph.nodes[des][newAttribute_path] = 1\n",
    "                if shortestPath == math.inf:\n",
    "                    graph.nodes[des][newAttribute_rescueSquad] = math.inf\n",
    "    return graph, voronoi\n",
    "\n",
    "def _addDisruption(graph, roads, newAttribute = 'weightWithDisruption', threshold = 3):\n",
    "    nx.set_edge_attributes(graph, nx.get_edge_attributes(graph, \"weight\"), newAttribute)\n",
    "    disruptedRoads = roads[roads['waterDepth'] >= threshold]['OBJECTID'].to_list()\n",
    "    for disruption in disruptedRoads:\n",
    "        for edge in graph.edges(disruption):\n",
    "            graph.edges()[edge][newAttribute] = math.inf # set edge weight to inf if it's disrupted by inundation\n",
    "    return graph\n",
    "\n",
    "def _changeValue4DisruptedRoad(roads, graph, threshold = 3):\n",
    "    # the disrupted road itself is not disconnected, so assign the shortestPath of adjancent road to this road\n",
    "    for disruption in roads[roads['waterDepth'] >= threshold]['OBJECTID'].to_list():\n",
    "        pathLen = []\n",
    "        edgeNum = []\n",
    "        for edge in graph.edges(disruption):\n",
    "            pathLen.append(graph.nodes()[edge[1]]['shortestPathLenWithDisruption'])\n",
    "            edgeNum.append(edge[1])\n",
    "        if pathLen != []: # in case there are disconnected single node\n",
    "            graph.nodes()[disruption]['shortestPathLenWithDisruption'] = min(pathLen)\n",
    "            if min(pathLen) != math.inf:\n",
    "                graph.nodes()[disruption]['rescueAssignedWithDisruption'] = edgeNum[pathLen.index(min(pathLen))]\n",
    "            else:\n",
    "                graph.nodes()[disruption]['rescueAssignedWithDisruption'] = np.nan\n",
    "    return graph\n",
    "\n",
    "def runRoutingWithDisruption(graph, rescue, roads):\n",
    "    graph, _ = _addPathLen2Graph(graph, rescue, 'weight', 'rescueAssigned', 'shortestPathLen')\n",
    "    graphDisrupted = _addDisruption(graph, roads, threshold = 1)\n",
    "    graph, _ = _addPathLen2Graph(graphDisrupted, rescue, 'weightWithDisruption', 'rescueAssignedWithDisruption', 'shortestPathLenWithDisruption') \n",
    "    graph = _changeValue4DisruptedRoad(roads, graph, threshold = 1)\n",
    "    return graph\n",
    "\n",
    "def getDisruptionRatio(graph):\n",
    "    nx.set_node_attributes(graph, \n",
    "                           {x[0]: y[1]/x[1] if y[1]/x[1] != math.inf else np.nan \\\n",
    "                            for x, y in zip(nx.get_node_attributes(graph, \"shortestPathLen\").items(), \n",
    "                                            nx.get_node_attributes(graph, \"shortestPathLenWithDisruption\").items() ) },\n",
    "                           'travelTimeIncreaseRatio')\n",
    "    roads['travelTimeIncreaseRatio'] = roads['OBJECTID'].map(nx.get_node_attributes(graph, \"travelTimeIncreaseRatio\"))    \n",
    "    return graph\n",
    "\n",
    "\n",
    "# calculate ratios\n",
    "graph = runRoutingWithDisruption(graph, rescue, roads)\n",
    "graph = getDisruptionRatio(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc827b3a",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ccdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation time prediction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef639b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample data\n",
    "def makeODmatrix(dataOneHourIndex, timeType = 'ResponseTime'):\n",
    "    dataOneHour = data.loc[dataOneHourIndex.index, :]\n",
    "    dataOneHour = dataOneHour.loc[:, ['OriginRoadID', 'DestinationID', timeType]]\n",
    "    dataOneHour = dataOneHour.groupby(by = ['OriginRoadID', 'DestinationID'], dropna = True).mean()\n",
    "    \n",
    "    ODmatrix_df = pd.DataFrame(index = rescue.OBJECTID_nearestRoad.values, columns = roads.OBJECTID.values)\n",
    "    for indexes in dataOneHour.index:\n",
    "        ODmatrix_df.loc[int(indexes[0]), int(indexes[1])] = dataOneHour.loc[indexes].values[0]\n",
    "    return ODmatrix_df.to_numpy()\n",
    "\n",
    "dataByHour = data.resample(pd.Timedelta(1, \"hour\"), closed = 'left', label = 'left', origin = 'end_day').apply(makeODmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0f96a74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallDateTime\n",
       "2016-01-01 00:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-01-01 01:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-01-01 02:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-01-01 03:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-01-01 04:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "                                             ...                        \n",
       "2016-10-15 19:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-10-15 20:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-10-15 21:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-10-15 22:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "2016-10-15 23:00:00    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...\n",
       "Freq: H, Length: 6936, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataByHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9643c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebfe351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "11.7\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487292f",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61ebe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "fig, ax = plt.subplots(figsize=(30, 7.5))\n",
    "t = range(len(dataTest_y_Flood))\n",
    "ax.plot(t, predictions, label = 'prediction')\n",
    "ax.plot(t, dataTest_y_Flood, label = 'ground truth')\n",
    "ax.set_xlabel('Incident', fontsize = 20)\n",
    "ax.set_ylabel('If accessible', fontsize = 20)\n",
    "ax.legend(fontsize = 20)\n",
    "ax.tick_params(axis='both', labelsize = 15)\n",
    "#ax.set_title('Prediction vs Ground truth', fontsize = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "print(classification_report(dataTest_y_Flood, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57790fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculateWaste (row):\n",
    "    if row['If accessible Real'] == 1 and row['If accessible Predicted'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculateUnknownDanger (row):\n",
    "    if row['If accessible Real'] == 0 and row['If accessible Predicted'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "    \n",
    "dataFlood = dataProcessed.loc['2016-10-09' : '2016-10-09']\n",
    "dataFlood['If accessible Real'] = dataFlood['Accessibility'].astype('int64')\n",
    "dataFlood['If accessible Predicted'] = [element[0] for element in predictions]\n",
    "dataFlood['Waste'] = dataFlood.apply(calculateWaste, axis = 1)\n",
    "dataFlood['Unknown Danger'] = dataFlood.apply(calculateUnknownDanger, axis = 1)\n",
    "dataFlood['Error Type'] = (dataFlood['Waste'] + dataFlood['Unknown Danger'] * 2).astype('string') # 1 mean wastes, 2 means potential danger\n",
    "dataFlood['Error Type'] = dataFlood['Error Type'].replace('1', 'Type 1').replace('2', 'Type 2')\n",
    "pd.set_option('display.max_rows', 20)\n",
    "display(dataFlood)\n",
    "\n",
    "# visualization\n",
    "px.set_mapbox_access_token(open(\"mapboxToken.txt\").read())\n",
    "fig1 = px.scatter_mapbox(dataFlood.loc[lambda df: df['Error Type'] != '0'], \n",
    "                        lat=\"latitude\", lon=\"longitude\",  \n",
    "                        color = \"Error Type\", #size = \"Response Time\",\n",
    "                        size_max = 15, zoom = 10, width = 575, height = 500)\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.scatter_mapbox(dataFlood.loc[lambda df: (df['Error Type'] != '0') &\n",
    "                                      (df['Error Type'] != '1')], \n",
    "                        lat=\"latitude\", lon=\"longitude\",  \n",
    "                        color = \"Error Type\", size = \"Response Time\",\n",
    "                        size_max = 30, zoom = 10, width = 550, height = 500)\n",
    "fig2.update_layout(showlegend=False)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "shp = gpd.read_file('./data/VB_City_Boundary.geojson')\n",
    "shp.crs = 'CRS84'\n",
    "\n",
    "# generate all points\n",
    "numOfPointsOneDimX = 50\n",
    "deltaX = shp.bounds.maxx - shp.bounds.minx\n",
    "deltaY = shp.bounds.maxy - shp.bounds.miny\n",
    "numOfPointsOneDimY = numOfPointsOneDimX * (deltaY / deltaX)\n",
    "\n",
    "xCorList = np.arange(float(shp.bounds.minx), float(shp.bounds.maxx), float(deltaX / numOfPointsOneDimX))\n",
    "yCorList = np.arange(float(shp.bounds.miny), float(shp.bounds.maxy), float(deltaY / numOfPointsOneDimY))\n",
    "xyPointList = [Point(x, y) for x in xCorList for y in yCorList]\n",
    "\n",
    "# select points within the city\n",
    "samplePoints = gpd.GeoSeries(xyPointList)\n",
    "samplePoints.crs = 'CRS84'\n",
    "withinOrNot = samplePoints.within(shp['geometry'].values[0])\n",
    "gdf = pd.concat([samplePoints, withinOrNot], axis = 1)\n",
    "gdf.crs = 'CRS84'\n",
    "gdfSelected = gdf.loc[gdf[1] == True]\n",
    "display(gdfSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the prediction for these points\n",
    "gdfSelected['latitude'] = gdfSelected[0].values.y\n",
    "gdfSelected['longitude'] = gdfSelected[0].values.x\n",
    "\n",
    "def addTimeFeature(gdf, hourInDay, dayOfWeek):\n",
    "    gdf_out = gdf.copy()\n",
    "    gdf_out['Hour in Day'] = hourInDay\n",
    "    gdf_out['Day of Week'] = dayOfWeek\n",
    "    return gdf_out\n",
    "\n",
    "gdfSelected_withTime = addTimeFeature(gdfSelected, 0, 6) #The day of week is 1, because it is the normalized value, flooding day is Sunday\n",
    "for hour in range(23):\n",
    "    gdfSelected_withTime = pd.concat([gdfSelected_withTime, addTimeFeature(gdfSelected, hour + 1, 6)])\n",
    "\n",
    "gdfForPrediction = gdfSelected_withTime.reset_index().loc[:,['latitude', 'longitude', 'Hour in Day']]\n",
    "gdfForPrediction_norm = normalizer(gdfForPrediction.copy())\n",
    "gdfForPrediction_norm['Day of Week'] = 1 #The day of week is 1, because it is the normalized value, flooding day is Sunday\n",
    "gdfForPrediction_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsFull = model.predict(gdfForPrediction_norm.values)\n",
    "predictionsFull = np.where(predictionsFull < 0.5, 0, 1).tolist()\n",
    "print(len(predictionsFull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFloodFull = gdfForPrediction.copy()\n",
    "dataFloodFull['If accessible'] = [element[0] for element in predictionsFull]\n",
    "dataFloodFull['If accessible'] = dataFloodFull['If accessible'].astype('string').replace('1', 'Accessible').replace('0', 'Inaccessible')\n",
    "display(dataFloodFull)\n",
    "\n",
    "# visualization\n",
    "px.set_mapbox_access_token(open(\"mapboxToken.txt\").read())\n",
    "fig = px.scatter_mapbox(dataFloodFull.loc[dataFloodFull['Hour in Day'] == 23], \n",
    "                        lat = \"latitude\", lon = \"longitude\",  \n",
    "                        color = \"If accessible\", #size = \"Response Time\",\n",
    "                        zoom = 9.5, opacity = 0.7, width = 600, height =700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "90a8183b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emsTravelTime]",
   "language": "python",
   "name": "conda-env-emsTravelTime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
